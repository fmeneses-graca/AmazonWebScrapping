{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJ9QUaki3B3oHlKXhmf6In",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fmeneses-graca/web_scrapping_scripts/blob/main/neo_financial_transactions_scrapper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "RukAnZeSIa7b"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Preparation: get HTML source code for financial transactions:\n",
        "## Create temp_transactions file google colab folder\n",
        "## Log into neo, find HTML div that holds all transactions (its called 'main')\n",
        "## Copy transactions source code to temp_transactions_html file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read (open/close) temp_transactions file with BeautifulSoup constructor \n",
        "\n",
        "with open(\"/content/temp_transactions_html\") as fp:\n",
        "    soup = BeautifulSoup(fp, 'html.parser')\n",
        "\n",
        "#print(soup)"
      ],
      "metadata": {
        "id": "AO1gKHXSTiF9"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from datetime import datetime\n",
        "\n",
        "with open('temp_transactions.csv', 'w', newline='', encoding='UTF8') as csv_file:\n",
        "  writer = csv.writer(csv_file)\n",
        "\n",
        "  header = ['Date', 'Description', 'Amount']\n",
        "  writer.writerow(header)\n",
        "\n",
        "  # loop through div elements that contain transaction content (date, description, amount)) \n",
        "  for div in soup.find_all('div', attrs={'data-item' : 'list-item-content'}):\n",
        "    # print(div)\n",
        "\n",
        "    # query to get transaction date\n",
        "    date = div.find('p', {'class' : 'MuiTypography-root typography-bodyS color-contentSubdued MuiTypography-body1'}).get_text() # get text\n",
        "    date = datetime.strptime(date,'%b %d').strftime('%d/%m/2023') # format date\n",
        "    print(date)\n",
        "    date_object = datetime.strptime(date, '%d/%m/%Y').date() # enforce date type\n",
        "    # print(type(date_object))\n",
        "    \n",
        "    # query to get transaction description\n",
        "    description = div.find('p', {'class' : 'MuiTypography-root typography-bodyL color-contentDefault MuiTypography-body1'}).get_text() # get text\n",
        "    description = description.replace('\\n', ' ').replace('                     ', ' ') # format text\n",
        "    # print(description)\n",
        "\n",
        "    # query to get transaction amount\n",
        "    amount = div.find('p', {'class' : 'MuiTypography-root typography-bodyL color-contentDefault jss1240 MuiTypography-body1'}).get_text() # get text\n",
        "    # print(amount) # test\n",
        "\n",
        "    # write row\n",
        "    data = [date_object, description, amount]\n",
        "    writer.writerow(data)\n",
        "\n",
        "# BUG FIX: class names and codes might change from time to time (e.g. MuiTypography-root typography-bodyL color-contentDefault jss1240 MuiTypography-body1)"
      ],
      "metadata": {
        "id": "alNeFQSK2sfT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}